{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/piqa/piqa_train.json\"\n",
    "val_path = \"../data/piqa/piqa_validation.json\"\n",
    "test_path = \"../data/piqa/piqa_test.json\"\n",
    "\n",
    "train_df = pd.read_json(train_path)\n",
    "val_df = pd.read_json(val_path)\n",
    "test_df = pd.read_json(test_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>sol1</th>\n",
       "      <th>sol2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When boiling butter, when it's ready, you can</td>\n",
       "      <td>Pour it onto a plate</td>\n",
       "      <td>Pour it into a jar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To permanently attach metal legs to a chair, y...</td>\n",
       "      <td>Weld the metal together to get it to stay firm...</td>\n",
       "      <td>Nail the metal together to get it to stay firm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do you indent something?</td>\n",
       "      <td>leave a space before starting the writing</td>\n",
       "      <td>press the spacebar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do you shake something?</td>\n",
       "      <td>move it up and down and side to side quickly.</td>\n",
       "      <td>stir it very quickly.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clean tires</td>\n",
       "      <td>Pour water, cape off caked on dirt. Use  speed...</td>\n",
       "      <td>Pour water, scrape off caked on dirt. Use a st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                goal  \\\n",
       "0      When boiling butter, when it's ready, you can   \n",
       "1  To permanently attach metal legs to a chair, y...   \n",
       "2                       how do you indent something?   \n",
       "3                        how do you shake something?   \n",
       "4                                        Clean tires   \n",
       "\n",
       "                                                sol1  \\\n",
       "0                               Pour it onto a plate   \n",
       "1  Weld the metal together to get it to stay firm...   \n",
       "2          leave a space before starting the writing   \n",
       "3      move it up and down and side to side quickly.   \n",
       "4  Pour water, cape off caked on dirt. Use  speed...   \n",
       "\n",
       "                                                sol2  label  \n",
       "0                                 Pour it into a jar      1  \n",
       "1  Nail the metal together to get it to stay firm...      0  \n",
       "2                                 press the spacebar      0  \n",
       "3                              stir it very quickly.      0  \n",
       "4  Pour water, scrape off caked on dirt. Use a st...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an intelligent assistant that helps evaluate practical solutions to everyday tasks and problems. Your role is to analyze solutions in a given context and determine which one is more effective and practical.\n",
      "\n",
      "Given a context and two possible solutions, choose the better solution that makes more sense for that context.\n",
      "\n",
      "Here are some important rules for the task:\n",
      "- Think carefully and logically about which solution is more appropriate for the given context\n",
      "- Consider practicality, safety, and effectiveness when evaluating the solutions\n",
      "- You must explain your reasoning for why your chosen solution is better\n",
      "- You must answer with <answer>0</answer> if Solution 1 is better, or <answer>1</answer> if Solution 2 is better\n",
      "- Put your final answer in <answer></answer> tags after your explanation\n",
      "\n",
      "Here are some examples:\n",
      "<example>\n",
      "\n",
      "<question>\n",
      "Based on the context, which solution is better?\n",
      "Context: When boiling butter, when it's ready, you can\n",
      "Solution 1: Pour it onto a plate\n",
      "Solution 2: Pour it into a jar\n",
      "</question>\n",
      "\n",
      "<response>\n",
      "Solution 1 is better because it's easier to clean up and it's more practical.\n",
      "Final answer: <answer>0</answer>\n",
      "</response>\n",
      "\n",
      "</example>\n",
      "\n",
      "Now, consider the following context and solutions, choose the better solution that makes more sense for that context.\n",
      "Context: {goal}\n",
      "\n",
      "Solution 1: {sol1}\n",
      "Solution 2: {sol2}\n"
     ]
    }
   ],
   "source": [
    "with open(\"prompt.txt\", \"r\") as file:\n",
    "    prompt = file.read()\n",
    "    \n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing imports ...\n",
    "from transformers import AutoTokenizer, AutoModelForCausalGeneration\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Move model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = [0, 1]  # Use GPUs 0 and 1\n",
    "    model = torch.nn.DataParallel(model, device_ids=device)\n",
    "    model = model.to(f'cuda:{device[0]}')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    model = model.to(device)\n",
    "\n",
    "def post_process(response):\n",
    "    pattern = r'<answer>(.*?)</answer>'\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_llama_response(row):\n",
    "    # Format the prompt with the current example\n",
    "    formatted_prompt = prompt.format(\n",
    "        goal=row['goal'],\n",
    "        sol1=row['sol1'], \n",
    "        sol2=row['sol2']\n",
    "    )\n",
    "    \n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device if isinstance(device, str) else f'cuda:{device[0]}')\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode and return response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for idx, row in val_df.iterrows():\n",
    "    response = get_llama_response(row)\n",
    "    final_answer = post_process(response)\n",
    "    res.append(final_answer) \n",
    "    \n",
    "val_df['llama_answer'] = res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv(\"llama_eval.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (val_df['llama_answer'] == val_df['label']).mean()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
